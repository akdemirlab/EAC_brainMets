{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b8ae6a-176f-47c0-8719-d4747f8b0556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.colors import ListedColormap\n",
    "import os\n",
    "from comut import comut\n",
    "from comut import fileparsers\n",
    "import palettable\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e9e121-1b0e-4258-acb6-152c370962de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "import csv\n",
    "\n",
    "# Define file paths\n",
    "input_tsv = '/Hartwig_mutational_sig_data.tsv'  # Path to the main TSV file\n",
    "sample_ids_tsv = '/Hartwig_Pt_Sample_ID.tsv'  # Path to the file containing sample IDs\n",
    "output_tsv = '/Hartwig_mutational_sig_data_filtered.tsv'  # Path to the output TSV file\n",
    "\n",
    "# Step 1: Read the sample IDs into a set\n",
    "with open(sample_ids_tsv, 'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t')  # Use DictReader to handle column names\n",
    "    sample_ids = {row['Sample ID'] for row in reader}  # Use the correct column name\n",
    "\n",
    "# Step 2: Filter the main TSV file\n",
    "with open(input_tsv, 'r') as infile, open(output_tsv, 'w', newline='') as outfile:\n",
    "    reader = csv.DictReader(infile, delimiter='\\t')\n",
    "    writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames, delimiter='\\t')\n",
    "\n",
    "    # Write header to the output file\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Filter rows based on sample IDs\n",
    "    for row in reader:\n",
    "        if row['sample_id'] in sample_ids:  # Use the correct column name\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c74f04-644e-4996-b987-65200e5a61a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Define file paths\n",
    "input_tsv = '/Hartwig_mutational_sig_data.tsv'  # Path to the main TSV file\n",
    "sample_ids_tsv = '/Hartwig_Pt_Sample_ID.tsv'  # Path to the file containing sample IDs\n",
    "output_tsv = '/Hartwig_mutational_sig_data_filtered.tsv'  # Path to the output TSV file\n",
    "\n",
    "# Step 1: Read the sample IDs in order from the ID file\n",
    "with open(sample_ids_tsv, 'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t')\n",
    "    sample_ids = [row['Sample ID'] for row in reader]  # Maintain order of Sample IDs\n",
    "\n",
    "# Step 2: Read and filter rows from the main TSV file\n",
    "with open(input_tsv, 'r') as infile:\n",
    "    reader = csv.DictReader(infile, delimiter='\\t')\n",
    "    fieldnames = reader.fieldnames  # Preserve original column order\n",
    "\n",
    "    # Store rows in a dictionary for fast lookup by Sample ID\n",
    "    rows_by_id = {row['sample_id']: row for row in reader if row['sample_id'] in sample_ids}\n",
    "\n",
    "# Step 3: Write rows in the order of sample IDs to the output file\n",
    "with open(output_tsv, 'w', newline='') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames, delimiter='\\t')\n",
    "\n",
    "    # Write the header to the output file\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write rows in the order of sample IDs from the ID file\n",
    "    for sample_id in sample_ids:\n",
    "        if sample_id in rows_by_id:  # Only write rows that exist in the main file\n",
    "            writer.writerow(rows_by_id[sample_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e32926-7efa-46f9-89b9-59c4ced9fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Define file paths\n",
    "filtered_tsv = '/Hartwig_mutational_sig_data_filtered.tsv'  # Input file with filtered and ordered rows\n",
    "output_contribution_tsv = '/Hartwig_mutational_sig_relative_contribution.tsv'  # Output file with relative contributions\n",
    "\n",
    "# Step 1: Read the filtered data\n",
    "with open(filtered_tsv, 'r') as infile:\n",
    "    reader = csv.DictReader(infile, delimiter='\\t')\n",
    "    fieldnames = reader.fieldnames\n",
    "\n",
    "    # Separate the Sample ID column from the signature columns\n",
    "    sample_id_col = 'sample_id'\n",
    "    signature_cols = [col for col in fieldnames if col != sample_id_col]\n",
    "\n",
    "    # Collect rows with normalized contributions\n",
    "    normalized_rows = []\n",
    "    for row in reader:\n",
    "        # Convert signature columns to floats\n",
    "        signature_values = [float(row[col]) for col in signature_cols]\n",
    "\n",
    "        # Calculate the sum of signature values\n",
    "        total = sum(signature_values)\n",
    "\n",
    "        # Normalize the values to get relative contributions\n",
    "        normalized_values = [value / total if total > 0 else 0 for value in signature_values]\n",
    "\n",
    "        # Create a new row with normalized values\n",
    "        normalized_row = {sample_id_col: row[sample_id_col]}\n",
    "        normalized_row.update({col: normalized_values[i] for i, col in enumerate(signature_cols)})\n",
    "\n",
    "        normalized_rows.append(normalized_row)\n",
    "\n",
    "# Step 2: Write the normalized data to a new file\n",
    "with open(output_contribution_tsv, 'w', newline='') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames, delimiter='\\t')\n",
    "\n",
    "    # Write the header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write the normalized rows\n",
    "    writer.writerows(normalized_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab5bc80-a790-4f20-a375-6d350e7b06bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Define file paths\n",
    "input_tsv = '/Hartwig_EACmets_drivergenes.tsv'  # Path to the main TSV file\n",
    "sample_ids_tsv = '/Hartwig_Pt_Sample_ID.tsv'  # Path to the file containing sample IDs\n",
    "output_tsv = '/Hartwig_EACmets_drivergenes_filtered.tsv'  # Path to the output TSV file\n",
    "\n",
    "# Step 1: Read the sample IDs into a set\n",
    "with open(sample_ids_tsv, 'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t')  # Use DictReader to handle column names\n",
    "    sample_ids = {row['Sample ID'] for row in reader}  # Use the correct column name\n",
    "\n",
    "# Step 2: Filter the main TSV file\n",
    "with open(input_tsv, 'r') as infile, open(output_tsv, 'w', newline='') as outfile:\n",
    "    reader = csv.DictReader(infile, delimiter='\\t')\n",
    "    writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames, delimiter='\\t')\n",
    "\n",
    "    # Write header to the output file\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Filter rows based on sample IDs\n",
    "    for row in reader:\n",
    "        if row['sampleId'] in sample_ids:  # Use the correct column name\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8575c-6173-4032-a9c9-48a1c55908f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "input_tsv = '/Hartwig_EACmets_drivergenes.tsv'  # Path to the main TSV file\n",
    "output_tsv = '/Hartwig_EACmets_drivergenes_filtered_wide.tsv'  # Path to the output TSV file\n",
    "from collections import defaultdict\n",
    "\n",
    "# Step 1: Process the data\n",
    "data = defaultdict(lambda: defaultdict(str))  # Nested dictionary to store mutation classes\n",
    "\n",
    "genes = set()  # To collect all unique gene names for columns\n",
    "\n",
    "with open(input_tsv, 'r') as infile:\n",
    "    reader = csv.DictReader(infile, delimiter='\\t')\n",
    "    \n",
    "    for row in reader:\n",
    "        sample_id = row['sampleId']\n",
    "        gene_name = row['gene']\n",
    "        mutation_class = row['mutationClass']\n",
    "\n",
    "        # Populate the data structure\n",
    "        data[sample_id][gene_name] = mutation_class\n",
    "        genes.add(gene_name)\n",
    "\n",
    "# Step 2: Create the wide-format data\n",
    "genes = sorted(genes)  # Sort gene names for consistent column order\n",
    "fieldnames = ['sampleId'] + genes  # Columns for the output file\n",
    "\n",
    "output_rows = []\n",
    "for sample_id, gene_data in data.items():\n",
    "    row = {'sampleId': sample_id}\n",
    "    # Add mutation classes under the respective gene columns\n",
    "    for gene in genes:\n",
    "        row[gene] = gene_data.get(gene, '')  # Use empty string if no data for the gene\n",
    "    output_rows.append(row)\n",
    "\n",
    "# Step 3: Write the wide-format data to a TSV file\n",
    "with open(output_tsv, 'w', newline='') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames, delimiter='\\t')\n",
    "\n",
    "    # Write header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write rows\n",
    "    writer.writerows(output_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9090f906-ed81-4008-89bd-87aae75aea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Define file paths\n",
    "input_tsv = '/DO_ID_WGS_id_PCAWG.tsv'  # Path to the main TSV file\n",
    "sample_ids_tsv = '/DO_filtered_PCAWG_list.tsv'  # Path to the file containing sample IDs\n",
    "output_tsv = '/DO_ID_WGS_id_PCAWG_filtered.tsv'  # Path to the output TSV file\n",
    "\n",
    "# Step 1: Read the sample IDs into a set\n",
    "with open(sample_ids_tsv, 'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t')  # Use DictReader to handle column names\n",
    "    sample_ids = {row['DO_filtered_list'] for row in reader}  # Use the correct column name\n",
    "\n",
    "# Step 2: Filter the main TSV file\n",
    "with open(input_tsv, 'r') as infile, open(output_tsv, 'w', newline='') as outfile:\n",
    "    reader = csv.DictReader(infile, delimiter='\\t')\n",
    "    writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames, delimiter='\\t')\n",
    "\n",
    "    # Write header to the output file\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Filter rows based on sample IDs\n",
    "    for row in reader:\n",
    "        if row['icgc_donor_id'] in sample_ids:  # Use the correct column name\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d5088-77cd-4920-a462-de4e071b4714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Define file paths\n",
    "input_tsv = '/PCAWG_driver_mutations_ICGC_EAC.tsv'  # Path to the main TSV file\n",
    "sample_ids_tsv = '/DO_ID_WGS_id_PCAWG_filtered.tsv'  # Path to the file containing sample IDs\n",
    "output_tsv = '/PCAWG_driver_mutations_ICGC_EAC_filtered.tsv'  # Path to the output TSV file\n",
    "\n",
    "# Step 1: Read the sample IDs into a set\n",
    "with open(sample_ids_tsv, 'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t')  # Use DictReader to handle column names\n",
    "    sample_ids = {row['tumor_wgs_aliquot_id'] for row in reader}  # Use the correct column name\n",
    "\n",
    "# Step 2: Filter the main TSV file\n",
    "with open(input_tsv, 'r') as infile, open(output_tsv, 'w', newline='') as outfile:\n",
    "    reader = csv.DictReader(infile, delimiter='\\t')\n",
    "    writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames, delimiter='\\t')\n",
    "\n",
    "    # Write header to the output file\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Filter rows based on sample IDs\n",
    "    for row in reader:\n",
    "        if row['sample_id'] in sample_ids:  # Use the correct column name\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb3671-e4f6-4651-a8c0-3743dfc056ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "input_tsv = '/PCAWG_driver_mutations_ICGC_EAC_filtered.tsv'  # Path to the main TSV file\n",
    "output_tsv = '/PCAWG_driver_mutations_ICGC_EAC_filtered_wide.tsv'  # Path to the output TSV file\n",
    "from collections import defaultdict\n",
    "\n",
    "# Step 1: Process the data\n",
    "data = defaultdict(lambda: defaultdict(str))  # Nested dictionary to store mutation classes\n",
    "\n",
    "genes = set()  # To collect all unique gene names for columns\n",
    "\n",
    "with open(input_tsv, 'r') as infile:\n",
    "    reader = csv.DictReader(infile, delimiter='\\t')\n",
    "    \n",
    "    for row in reader:\n",
    "        sample_id = row['sample_id']\n",
    "        gene_name = row['gene']\n",
    "        mutation_class = row['category']\n",
    "\n",
    "        # Populate the data structure\n",
    "        data[sample_id][gene_name] = mutation_class\n",
    "        genes.add(gene_name)\n",
    "\n",
    "# Step 2: Create the wide-format data\n",
    "genes = sorted(genes)  # Sort gene names for consistent column order\n",
    "fieldnames = ['sample_id'] + genes  # Columns for the output file\n",
    "\n",
    "output_rows = []\n",
    "for sample_id, gene_data in data.items():\n",
    "    row = {'sample_id': sample_id}\n",
    "    # Add mutation classes under the respective gene columns\n",
    "    for gene in genes:\n",
    "        row[gene] = gene_data.get(gene, '')  # Use empty string if no data for the gene\n",
    "    output_rows.append(row)\n",
    "\n",
    "# Step 3: Write the wide-format data to a TSV file\n",
    "with open(output_tsv, 'w', newline='') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames, delimiter='\\t')\n",
    "\n",
    "    # Write header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write rows\n",
    "    writer.writerows(output_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebefa548-86da-433c-b664-d03086243b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Define file paths\n",
    "input_tsv = '/PCAWG_signatures_fileID.tsv'  # Path to the main TSV file\n",
    "sample_ids_tsv = '/DO_ID_WGS_id_PCAWG_filtered.tsv'  # Path to the file containing sample IDs\n",
    "output_tsv = '/PCAWG_signatures_filtered.tsv'  # Path to the output TSV file\n",
    "\n",
    "# Step 1: Read the sample IDs in order from the ID file\n",
    "with open(sample_ids_tsv, 'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t')\n",
    "    sample_ids = [row['tumor_wgs_aliquot_id'] for row in reader]  # Maintain order of Sample IDs\n",
    "\n",
    "# Step 2: Read and filter rows from the main TSV file\n",
    "with open(input_tsv, 'r') as infile:\n",
    "    reader = csv.DictReader(infile, delimiter='\\t')\n",
    "    fieldnames = reader.fieldnames  # Preserve original column order\n",
    "\n",
    "    # Store rows in a dictionary for fast lookup by Sample ID\n",
    "    rows_by_id = {row['file_id']: row for row in reader if row['file'] in sample_ids}\n",
    "\n",
    "# Step 3: Write rows in the order of sample IDs to the output file\n",
    "with open(output_tsv, 'w', newline='') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames, delimiter='\\t')\n",
    "\n",
    "    # Write the header to the output file\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write rows in the order of sample IDs from the ID file\n",
    "    for sample_id in sample_ids:\n",
    "        if sample_id in rows_by_id:  # Only write rows that exist in the main file\n",
    "            writer.writerow(rows_by_id[sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d05f60-7664-4a95-b785-b93098e6cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "input_tsv = '/PCAWG_driver_mutations_ICGC_EAC_filtered_wide.tsv'  # Path to the main TSV file\n",
    "sample_ids_tsv = '/COMUT_plot_input_files/DO_ID_WGS_id_PCAWG_filtered.tsv'  # Path to the file containing sample IDs\n",
    "output_tsv = '/PCAWG_driver_mutations_ICGC_EAC_filtered_wide-updated.tsv'  # Path to the output TSV file\n",
    "\n",
    "import csv\n",
    "\n",
    "# Step 1: Read the sample IDs in order from the ID file\n",
    "with open(sample_ids_tsv, 'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t')\n",
    "    sample_ids = [row['tumor_wgs_aliquot_id'] for row in reader]  # Maintain order of Sample IDs\n",
    "\n",
    "# List of columns to keep\n",
    "columns_to_keep = ['ERBB2', 'EGFR', 'CCND1', 'TP53', 'JAK2']\n",
    "\n",
    "# Step 2: Read and filter rows from the main TSV file\n",
    "with open(input_tsv, 'r') as infile:\n",
    "    reader = csv.DictReader(infile, delimiter='\\t')\n",
    "    fieldnames = reader.fieldnames  # Preserve original column order\n",
    "    \n",
    "    # Filter out columns that are not in `columns_to_keep`\n",
    "    fieldnames_to_write = ['sample_id'] + [col for col in columns_to_keep if col in fieldnames]\n",
    "    \n",
    "    # Store rows in a dictionary for fast lookup by Sample ID\n",
    "    rows_by_id = {row['sample_id']: row for row in reader if row['sample_id'] in sample_ids}\n",
    "\n",
    "# Step 3: Write rows in the order of sample IDs to the output file\n",
    "with open(output_tsv, 'w', newline='') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames_to_write, delimiter='\\t')\n",
    "\n",
    "    # Write the header to the output file\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write rows in the order of sample IDs from the ID file\n",
    "    for sample_id in sample_ids:\n",
    "        if sample_id in rows_by_id:  # Only write rows that exist in the main file\n",
    "            # Filter the row to keep only the desired columns\n",
    "            filtered_row = {key: rows_by_id[sample_id][key] for key in fieldnames_to_write}\n",
    "            writer.writerow(filtered_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d7de8d-cc61-4f17-b1da-d6efc43edc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_genes_wide = pd.read_csv('/driver_gene_all_samples_long.csv')\n",
    "\n",
    "\n",
    "# Step 2: Reshape the data into long format using pd.melt\n",
    "driver_genes_mut = pd.melt(driver_genes_wide, \n",
    "                  id_vars=['Sample ID'],  # Keep 'Sample ID' as identifier\n",
    "                  value_vars=['EGFR alteration', 'CCND1 alteration', 'ERBB2 alteration', 'TP53 alteration', 'JAK2 alteration'], \n",
    "                  var_name='category',  # New column for the gene name\n",
    "                  value_name='value')   # New column for the alteration values\n",
    "\n",
    "# Step 3: Rename columns to match desired output\n",
    "driver_genes_mut = driver_genes_mut.rename(columns={'Sample ID': 'sample'})\n",
    "\n",
    "# Step 4: Remove \" alteration\" from the gene names in the 'category' column\n",
    "driver_genes_mut['category'] = driver_genes_mut['category'].str.replace(' alteration', '', regex=False)\n",
    "\n",
    "\n",
    "driver_genes_mut.to_csv('/comut_driver_genes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc1c103-d160-4b99-9f91-a294fa4453f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load data\n",
    "\n",
    "#load\n",
    "data = pd.read_csv('/All_sample_metadata.csv')\n",
    "data_WGD = pd.read_csv('/comut_WGD.csv')\n",
    "driver_genes_mut = pd.read_csv('/comut_driver_genes_filtered_by_driver_likelihood.csv')\n",
    "data_mutsig = pd.read_csv('/comut_mutsig_contribution.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126bb4be-248e-4f89-9a5f-2ff2424e0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library and functions\n",
    "def plot_categorical(comut, data, name, column, mapping = None):\n",
    "    data = data.copy()\n",
    "    data['category'] = name\n",
    "    data['value'] = data[column]\n",
    "    comut.add_categorical_data(data, name = name, mapping = mapping)\n",
    "\n",
    "def plot_continuous(comut, data, name, column, mapping, cat_mapping, value_range):\n",
    "    data = data.copy()\n",
    "    data['category'] = name\n",
    "    data['value'] = data[column]\n",
    "    comut.add_continuous_data(data, name = name, mapping = mapping, cat_mapping = cat_mapping, value_range = value_range)\n",
    "\n",
    "def plot_bar(comut, data, name, columns, mapping=None):\n",
    "    data = data.copy()\n",
    "    data = data[['sample']+columns]\n",
    "    comut.add_bar_data(data, stacked = True, name = name, ylabel = name, mapping=mapping)\n",
    "    \n",
    "def plot_scatter(comut, data, name, columns, mapping=None, scatter_kwargs=None):\n",
    "    data = data.copy()\n",
    "    data = data[['sample']+columns]\n",
    "    comut.add_scatter_data(data, stacked = True, name = name, ylabel = name, mapping=mapping, scatter_kwargs=scatter_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd34c800-b0a8-4d65-a101-41746f25ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "purp_7 = palettable.cartocolors.sequential.Purp_7.mpl_colormap\n",
    "vivid_10 = palettable.cartocolors.qualitative.Vivid_10.mpl_colors\n",
    "balance_6 = palettable.cmocean.diverging.Balance_6.mpl_colors\n",
    "\n",
    "from matplotlib import rcParams\n",
    "custom_rcParams = {\n",
    "    'font.family': 'Arial',\n",
    "    'font.size': 13,\n",
    "    'axes.labelsize': 13,\n",
    "    'legend.fontsize':9,\n",
    "    'xtick.labelsize': 7,\n",
    "    'ytick.labelsize': 9\n",
    "}\n",
    "\n",
    "# update rcParams\n",
    "rcParams.update(custom_rcParams)\n",
    "\n",
    "data['sample'] = data['Sample ID']\n",
    "data[\"Group\"] = data[\"Group\"].astype(\"category\")\n",
    "data.Group = pd.Categorical(data.Group, \n",
    "                    categories=['EAC Brain Mets', 'PCAWG Primary EAC', 'Hartwig EAC Mets'],\n",
    "                    ordered=True)\n",
    "data.sort_values(by=['Group', 'SNV count'], ascending=[True,False], inplace=True)\n",
    "data['snv_overlap'] = data['SNV count'].clip(upper=200_000)\n",
    "\n",
    "comut1 = comut.CoMut()\n",
    "\n",
    "\n",
    "# Now proceed with plotting\n",
    "plot_categorical(comut1, data, \"Location\", 'Location', \n",
    "                 mapping={'Esophagus': '#C86050', \n",
    "                          'Brain Met': '#6685c2', \n",
    "                          'Esophageal Met': '#f1b6da', \n",
    "                          'Liver Met': '#fee391', \n",
    "                          'Lymph Met': '#fdb863', \n",
    "                          'Lung Met': '#d8daeb',\n",
    "                          'Other Met': '#F3BF5A', })  \n",
    "\n",
    "#Driver genes\n",
    "def plot_snv_and_cnv(comut1, data, driver_genes_mut):\n",
    "    vivid_10 = palettable.cartocolors.qualitative.Vivid_10.mpl_colors\n",
    "\n",
    "    gene_list = ['TP53','ERBB2','EGFR','CCND1','JAK2']\n",
    "        \n",
    "\n",
    "    driver_genes_mut.sort_values(by=\"category\", key=lambda column: column.map(lambda e: gene_list.index(e)), inplace=True, ascending=False)\n",
    "\n",
    "    driver_genes = driver_genes_mut[driver_genes_mut['value'].notnull()]\n",
    "\n",
    "    mut_mapping = {'Mutation': {'facecolor':'#BCDD78','edgecolor': 'white'}, \n",
    "                    'Deletion': {'facecolor':'#8AB0D0', 'edgecolor': 'white', 'linewidth': 0.75},\n",
    "                    'Amplification': {'facecolor':'#EB8777', 'edgecolor': 'white', 'linewidth': 0.75}, 'No data': 'white', 'No alteration':'white',\n",
    "                   }\n",
    "    \n",
    "    comut1.add_categorical_data(driver_genes, name = \"Driver Gene Alterations\", mapping = mut_mapping)\n",
    "\n",
    "plot_snv_and_cnv(comut1, driver_genes_mut, driver_genes_mut)\n",
    "\n",
    "plot_categorical(comut1, data, \"WGD\",'WGD status', mapping={'Yes':\"#4d4d4d\",'No':'#ffffff'})\n",
    "\n",
    "\n",
    "\n",
    "plot_bar(comut1, data, \"SV count\", ['SV count'],  mapping={'SV count': '#EB8777'})\n",
    "\n",
    "#SNV\n",
    "data_mutsig['sample'] = data_mutsig['Sample ID']\n",
    "\n",
    "plot_bar(comut1, data_mutsig, 'MutSig',  ['MutSig 17',  'Other'],mapping={'MutSig 17':'#01665e', 'Other':'#f5f5f5'})\n",
    "\n",
    "\n",
    "# Cap SNV count values in the data\n",
    "data['SNV count'] = data['SNV count'].clip(upper=80000) \n",
    "\n",
    "\n",
    "plot_bar(comut1, data, 'SNV count', ['SNV count'], mapping={'SNV count': '#ab7ca3'})\n",
    "\n",
    "#groups\n",
    "plot_categorical(comut1, data, \"Group\",'Group', mapping={'PCAWG Primary EAC':'#C86050', 'Hartwig EAC Mets':'#F3BF5A', 'EAC Brain Mets':'#6685c2'})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### plot\n",
    "\n",
    "\n",
    "heights = {'SNV': 5}\n",
    "hspace = 0.08\n",
    "wspace = 0.05\n",
    "\n",
    "comut1.plot_comut(figsize = (14,8), x_padding = 0.08, y_padding = 0.07, tri_padding = 0.08, heights=heights,\n",
    "                hspace = hspace, \n",
    "                wspace= wspace)\n",
    "\n",
    "comut1.add_unified_legend(ncol = 1)\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "output_file = \"/comut_PCAWG_Hartwig_BrainmetEAC_plot.png\"\n",
    "plt.savefig(output_file, dpi=300, bbox_inches='tight')  # Save with high resolution\n",
    "print(f\"Plot saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
